{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert the Cross-Recessed-Screw data from individual xml labels into a combined coco Json format\n",
    "# Run that script seperately if the conversion is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm2abs(bbx_coords, image_shape):\n",
    "    x, y, w, h, = bbx_coords\n",
    "\n",
    "    # get x and y\n",
    "    x_reg = int(x * image_shape[1])\n",
    "    y_reg = int(y * image_shape[0])\n",
    "    w_reg = int(w * image_shape[1])\n",
    "    h_reg = int(h * image_shape[0])\n",
    "\n",
    "    bbx_coords_reg = [x_reg, y_reg, w_reg, h_reg]\n",
    "    return bbx_coords_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1003, 1275) (1418, 1628)\n",
      "\n",
      "\n",
      "Image details: {'name': '000001.jpg', 'id': 1}\n",
      "Label details: {'id': 1, 'image_id': 1, 'category_id': 2, 'segmentation': [[1003, 1275, 1003, 1628, 1418, 1628, 1418, 1275]], 'area': 146495, 'bbox': [1003, 1275, 415, 353], 'iscrowd': 0}\n",
      "Zero area bounding box found in image 000001.jpg\n",
      "Dimensions 000001.jpg: (3036, 4048, 3)\n",
      "(1346, 391) (1545, 606)\n",
      "\n",
      "\n",
      "Image details: {'name': '000002.jpg', 'id': 2}\n",
      "Label details: {'id': 2, 'image_id': 2, 'category_id': 2, 'segmentation': [[1346, 391, 1346, 606, 1545, 606, 1545, 391]], 'area': 42785, 'bbox': [1346, 391, 199, 215], 'iscrowd': 0}\n",
      "(1324, 3299) (1506, 3442)\n",
      "\n",
      "\n",
      "Image details: {'name': '000002.jpg', 'id': 2}\n",
      "Label details: {'id': 3, 'image_id': 2, 'category_id': 2, 'segmentation': [[1324, 3299, 1324, 3442, 1506, 3442, 1506, 3299]], 'area': 26026, 'bbox': [1324, 3299, 182, 143], 'iscrowd': 0}\n",
      "Zero area bounding box found in image 000002.jpg\n",
      "Dimensions 000002.jpg: (4048, 3036, 3)\n",
      "(550, 1966) (710, 2121)\n",
      "\n",
      "\n",
      "Image details: {'name': '000003.jpg', 'id': 3}\n",
      "Label details: {'id': 4, 'image_id': 3, 'category_id': 2, 'segmentation': [[550, 1966, 550, 2121, 710, 2121, 710, 1966]], 'area': 24800, 'bbox': [550, 1966, 160, 155], 'iscrowd': 0}\n",
      "(1904, 1259) (2064, 1430)\n",
      "\n",
      "\n",
      "Image details: {'name': '000003.jpg', 'id': 3}\n",
      "Label details: {'id': 5, 'image_id': 3, 'category_id': 2, 'segmentation': [[1904, 1259, 1904, 1430, 2064, 1430, 2064, 1259]], 'area': 27360, 'bbox': [1904, 1259, 160, 171], 'iscrowd': 0}\n",
      "(1655, 3194) (1821, 3370)\n",
      "\n",
      "\n",
      "Image details: {'name': '000003.jpg', 'id': 3}\n",
      "Label details: {'id': 6, 'image_id': 3, 'category_id': 2, 'segmentation': [[1655, 3194, 1655, 3370, 1821, 3370, 1821, 3194]], 'area': 29216, 'bbox': [1655, 3194, 166, 176], 'iscrowd': 0}\n",
      "Zero area bounding box found in image 000003.jpg\n",
      "Dimensions 000003.jpg: (4048, 3036, 3)\n",
      "(1677, 1690) (1887, 1867)\n",
      "\n",
      "\n",
      "Image details: {'name': '000004.jpg', 'id': 4}\n",
      "Label details: {'id': 7, 'image_id': 4, 'category_id': 2, 'segmentation': [[1677, 1690, 1677, 1867, 1887, 1867, 1887, 1690]], 'area': 37170, 'bbox': [1677, 1690, 210, 177], 'iscrowd': 0}\n",
      "(1180, 2154) (1401, 2353)\n",
      "\n",
      "\n",
      "Image details: {'name': '000004.jpg', 'id': 4}\n",
      "Label details: {'id': 8, 'image_id': 4, 'category_id': 2, 'segmentation': [[1180, 2154, 1180, 2353, 1401, 2353, 1401, 2154]], 'area': 43979, 'bbox': [1180, 2154, 221, 199], 'iscrowd': 0}\n",
      "Zero area bounding box found in image 000004.jpg\n",
      "Dimensions 000004.jpg: (4048, 3036, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check image dimensions, bounding box coordinates and labels\n",
    "# We will compare the normalised and absolute coordinates, we assume the two json files are keyed identically\n",
    "root = 'C:/Users/drago/Documents/gitrepos/Cross-Recessed-Screw_Deep-Learning-Datasets/'\n",
    "directory = root + 'Training_Images/'\n",
    "check_shape = False\n",
    "\n",
    "#abs_labels_dir = root + 'Completed_Labels.json'\n",
    "abs_labels_dir = root + 'Training_Annotations/coco.json'\n",
    "\n",
    "# Open the json file containing the absolute labels\n",
    "with open(abs_labels_dir) as abs_labels_json:\n",
    "    abs_labels_dict = json.load(abs_labels_json)\n",
    "\n",
    "# Iterate through each image in abs_labels, extracting filename and id\n",
    "for file in [{'name': image['file_name'].split('/')[-1], 'id': image['id']} for image in abs_labels_dict['images'][:]]:\n",
    "    if file['name'].endswith('.png') or file['name'].endswith('.jpg'):\n",
    "        # Read in the image\n",
    "        dataset_img = cv2.imread(directory + file['name'])\n",
    "        \n",
    "        # Extract the bounding boxes for each screw in the image\n",
    "        label_ids = []\n",
    "        for index, abs_label in enumerate(abs_labels_dict['annotations'][:]):\n",
    "            # Find the annotations that match the image\n",
    "            # I want to know which images have annotations of area zero\n",
    "            if abs_label['image_id'] == file['id']:\n",
    "\n",
    "                # Read in absolute bounding box coordinates\n",
    "                coordinates = abs_label['bbox']\n",
    "\n",
    "                #Display image with bounding box\n",
    "                start_point = (int(coordinates[0]), int(coordinates[1]))\n",
    "                end_point = (int(coordinates[0] + coordinates[2]), int(coordinates[1] + coordinates[3]))\n",
    "                \n",
    "                print(start_point, end_point)\n",
    "                print('\\n')\n",
    "\n",
    "                if abs_label['category_id'] == 2:\n",
    "                    colour = (0, 0, 255)\n",
    "                if abs_label['category_id'] == 4:\n",
    "                    colour = (255, 0, 0)\n",
    "                # draw the rectangle\n",
    "                cv2.rectangle(dataset_img, start_point, end_point, color=colour, thickness= 1, lineType=cv2.LINE_8)\n",
    "\n",
    "                print(\"Image details: {}\".format(file))\n",
    "                print(\"Label details: {}\".format(abs_label))\n",
    "\n",
    "        print(\"Zero area bounding box found in image {}\".format(file['name']))\n",
    "        # display the output\n",
    "        print(\"Dimensions {}: {}\".format(file['name'], dataset_img.shape))\n",
    "        cv2.imshow('imageRectangle', dataset_img)\n",
    "        if cv2.waitKey(0) == 27: break\n",
    "        else: continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# # Check Github dataset iamge dimensions\n",
    "# directory = 'C:/Users/drago/Documents/gitrepos/Cross-Recessed-Screw_Deep-Learning-Datasets/Training_Images/'\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         dataset_img = cv2.imread(directory + filename)\n",
    "        \n",
    "#         print(\"Dimensions {}: {}\", (filename, dataset_img.shape))\n",
    "#         continue\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "# directory = 'C:/Users/drago/Documents/gitrepos/Cross-Recessed-Screw_Deep-Learning-Datasets/Training_Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert git dataset to 480x640 dimensions\n",
    "size = 480, 640\n",
    "\n",
    "for infile in glob.glob(directory + \"*.jpg\"):\n",
    "    file, ext = os.path.splitext(infile)\n",
    "    file_name = os.path.basename(file)\n",
    "    with Image.open(infile) as im:\n",
    "        # When the image is in portrait mode, scale by flipped dimensions\n",
    "        if im.size[0] > im.size[1]:\n",
    "            im.thumbnail((640, 480))\n",
    "        else:\n",
    "            im.thumbnail((480, 640))\n",
    "        \n",
    "        im.save(directory + 'thumbnail/' + file_name + '.jpg', \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check those dimensions match all images within their respective dataset\n",
    "# NOTE: There are some rotated 90 deg\n",
    "# Now, think of some creative way to handle the difference between the image sizes,\n",
    "#  the new cameras image size and the size of model needed to take these as inputs?\n",
    "# Do I need to scale down the size of the images for prediction? How would I make use of the predictions?\n",
    "#  Would scaling them actually work?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
